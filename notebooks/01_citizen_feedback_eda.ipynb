{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Citizen Feedback Text Analysis: Exploratory Data Analysis\n",
        "\n",
        "This notebook demonstrates the complete pipeline for analyzing citizen feedback about public services in Nigeria.\n",
        "\n",
        "**Contents:**\n",
        "1. Data Generation & Loading\n",
        "2. Text Cleaning & Preprocessing\n",
        "3. Exploratory Data Analysis\n",
        "4. Sentiment Analysis\n",
        "5. Topic Modeling\n",
        "6. Combined Analysis & Insights\n",
        "7. Export Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Project modules\n",
        "from src.data.generate_synthetic_feedback import generate_synthetic_feedback, save_to_csv\n",
        "from src.text.cleaning import clean_text_df\n",
        "from src.text.features import compute_tfidf_features, get_top_keywords, compute_text_statistics\n",
        "from src.text.sentiment import compute_sentiment, get_sentiment_summary\n",
        "from src.text.topic_modeling import fit_topics, print_topics, save_topic_assignments\n",
        "from src.viz.plots import (\n",
        "    plot_topic_trends, plot_sentiment_trends, plot_top_keywords,\n",
        "    plot_topic_sentiment_heatmap, plot_channel_distribution,\n",
        "    plot_state_distribution, plot_word_length_distribution\n",
        ")\n",
        "\n",
        "# Plotting setup\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print('\u2713 All imports successful')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Generation & Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if data already exists\n",
        "data_path = Path('data/raw/citizen_feedback.csv')\n",
        "\n",
        "if not data_path.exists():\n",
        "    print('Generating synthetic data...')\n",
        "    records = generate_synthetic_feedback(n=50000, months=24, seed=42)\n",
        "    save_to_csv(records, data_path)\n",
        "    print(f'\u2713 Data generated and saved to {data_path}')\n",
        "else:\n",
        "    print(f'\u2713 Data already exists at {data_path}')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(data_path)\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "\n",
        "print(f'\\nDataset shape: {df.shape}')\n",
        "print(f'Columns: {list(df.columns)}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Dataset Information:')\n",
        "print('='*60)\n",
        "df.info()\n",
        "\n",
        "print('\\nMissing Values:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print('\\nDate Range:')\n",
        "print(f'Start: {df[\"created_at\"].min()}')\n",
        "print(f'End: {df[\"created_at\"].max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Text Cleaning & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample raw messages\n",
        "print('Sample Raw Messages:')\n",
        "print('='*60)\n",
        "for idx in range(5):\n",
        "    print(f'\\n[{idx+1}] {df.iloc[idx][\"raw_text\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean text\n",
        "df_clean = clean_text_df(df, text_col='raw_text')\n",
        "\n",
        "print('\\nCleaning Results:')\n",
        "print(f'Original records: {len(df):,}')\n",
        "print(f'After cleaning: {len(df_clean):,}')\n",
        "print(f'Removed: {len(df) - len(df_clean):,} records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show cleaned messages with PII masking examples\n",
        "print('Sample Cleaned Messages (with PII masking):')\n",
        "print('='*60)\n",
        "for idx in range(5):\n",
        "    print(f'\\n[{idx+1}] Original: {df_clean.iloc[idx][\"raw_text\"]}')\n",
        "    print(f'    Cleaned:  {df_clean.iloc[idx][\"cleaned_text\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Channel Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_channel_distribution(df_clean, output_path=Path('reports/figures/channel_dist.png'), show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### State Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_state_distribution(df_clean, top_n=15, output_path=Path('reports/figures/state_dist.png'), show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Department Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dept_counts = df_clean['assigned_dept'].value_counts()\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "dept_counts.plot.bar(ax=ax, color='steelblue')\n",
        "ax.set_xlabel('Department')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Feedback by Department')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('reports/figures/dept_dist.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Message Length Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_word_length_distribution(df_clean, output_path=Path('reports/figures/length_dist.png'), show=True)\n",
        "\n",
        "print('\\nText Length Statistics:')\n",
        "print(df_clean['word_count'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temporal Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean['month'] = df_clean['created_at'].dt.to_period('M')\n",
        "monthly_counts = df_clean.groupby('month').size()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 5))\n",
        "monthly_counts.plot(ax=ax, marker='o', linewidth=2)\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Feedback Count')\n",
        "ax.set_title('Feedback Volume Over Time')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('reports/figures/temporal_trend.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rating Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter non-empty ratings\n",
        "rated = df_clean[df_clean['rating'].notna() & (df_clean['rating'] != '')]\n",
        "rated['rating'] = pd.to_numeric(rated['rating'], errors='coerce')\n",
        "rated = rated[rated['rating'] > 0]\n",
        "\n",
        "if len(rated) > 0:\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    rated['rating'].value_counts().sort_index().plot.bar(ax=ax, color='coral')\n",
        "    ax.set_xlabel('Rating')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title('Rating Distribution (1=worst, 5=best)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('reports/figures/rating_dist.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f'\\nRatings provided: {len(rated):,} ({len(rated)/len(df_clean)*100:.1f}%)')\n",
        "    print(f'Average rating: {rated[\"rating\"].mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute sentiment\n",
        "df_clean = compute_sentiment(df_clean, text_col='cleaned_text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall sentiment summary\n",
        "print('Overall Sentiment Distribution:')\n",
        "print('='*60)\n",
        "print(df_clean['sentiment_label'].value_counts())\n",
        "print('\\nSentiment Statistics:')\n",
        "print(get_sentiment_summary(df_clean))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment by channel\n",
        "print('\\nSentiment by Channel:')\n",
        "print('='*60)\n",
        "print(get_sentiment_summary(df_clean, group_by='channel'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment examples\n",
        "print('\\nSample Positive Feedback:')\n",
        "print('='*60)\n",
        "for idx, row in df_clean[df_clean['sentiment_label'] == 'positive'].head(3).iterrows():\n",
        "    print(f'[{row[\"sentiment_score\"]:.2f}] {row[\"cleaned_text\"][:150]}...')\n",
        "\n",
        "print('\\nSample Negative Feedback:')\n",
        "print('='*60)\n",
        "for idx, row in df_clean[df_clean['sentiment_label'] == 'negative'].head(3).iterrows():\n",
        "    print(f'[{row[\"sentiment_score\"]:.2f}] {row[\"cleaned_text\"][:150]}...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment trends\n",
        "plot_sentiment_trends(\n",
        "    df_clean,\n",
        "    by='national',\n",
        "    output_path=Path('reports/figures/sentiment_trends.png'),\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit topic model\n",
        "topic_result = fit_topics(\n",
        "    df_clean,\n",
        "    text_col='cleaned_text',\n",
        "    n_topics=10,\n",
        "    method='lda',\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print topics\n",
        "print_topics(topic_result, n_words=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add topic assignments to dataframe\n",
        "df_clean['dominant_topic'] = topic_result['dominant_topics']\n",
        "\n",
        "# Topic distribution\n",
        "topic_dist = df_clean['dominant_topic'].value_counts().sort_index()\n",
        "print('\\nTopic Distribution:')\n",
        "print(topic_dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topic trends over time\n",
        "plot_topic_trends(\n",
        "    df_clean,\n",
        "    topic_col='dominant_topic',\n",
        "    output_path=Path('reports/figures/topic_trends.png'),\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Combined Analysis & Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topic \u00d7 Sentiment heatmap\n",
        "plot_topic_sentiment_heatmap(\n",
        "    df_clean,\n",
        "    output_path=Path('reports/figures/topic_sentiment_heatmap.png'),\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Topic by channel\n",
        "topic_channel = pd.crosstab(df_clean['dominant_topic'], df_clean['channel'], normalize='columns')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(topic_channel, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax)\n",
        "ax.set_xlabel('Channel')\n",
        "ax.set_ylabel('Topic')\n",
        "ax.set_title('Topic Distribution by Channel')\n",
        "plt.tight_layout()\n",
        "plt.savefig('reports/figures/topic_channel_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract top keywords\n",
        "texts = df_clean['cleaned_text'].tolist()\n",
        "tfidf_matrix, vectorizer, feature_names = compute_tfidf_features(texts)\n",
        "top_keywords = get_top_keywords(tfidf_matrix, feature_names, top_n=20)\n",
        "\n",
        "plot_top_keywords(\n",
        "    top_keywords,\n",
        "    output_path=Path('reports/figures/top_keywords.png'),\n",
        "    show=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Key Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('KEY INSIGHTS')\n",
        "print('='*60)\n",
        "\n",
        "print('\\n1. VOLUME')\n",
        "print(f'   Total messages: {len(df_clean):,}')\n",
        "print(f'   Top channel: {df_clean[\"channel\"].value_counts().index[0]}')\n",
        "print(f'   Top state: {df_clean[\"state\"].value_counts().index[0]}')\n",
        "\n",
        "print('\\n2. SENTIMENT')\n",
        "neg_pct = (df_clean['sentiment_label'] == 'negative').sum() / len(df_clean) * 100\n",
        "print(f'   Negative feedback: {neg_pct:.1f}%')\n",
        "print(f'   Average sentiment score: {df_clean[\"sentiment_score\"].mean():.3f}')\n",
        "\n",
        "print('\\n3. TOPICS')\n",
        "top_topic = df_clean['dominant_topic'].value_counts().index[0]\n",
        "top_topic_pct = df_clean['dominant_topic'].value_counts().iloc[0] / len(df_clean) * 100\n",
        "print(f'   Most common topic: {top_topic} ({top_topic_pct:.1f}%)')\n",
        "\n",
        "print('\\n4. RESPONSE')\n",
        "resolved = df_clean[df_clean['resolved'] == 'True']\n",
        "resolution_rate = len(resolved) / len(df_clean) * 100\n",
        "print(f'   Resolution rate: {resolution_rate:.1f}%')\n",
        "if 'response_time_days' in df_clean.columns:\n",
        "    resolved_times = pd.to_numeric(resolved['response_time_days'], errors='coerce')\n",
        "    avg_response = resolved_times.mean()\n",
        "    print(f'   Avg response time: {avg_response:.1f} days')\n",
        "\n",
        "print('\\n5. RECOMMENDATIONS')\n",
        "print('   \u2022 Focus on top 3 topics for quick wins')\n",
        "print('   \u2022 Improve response time for SMS/Hotline channels')\n",
        "print('   \u2022 Address negative sentiment clusters in specific states')\n",
        "print('   \u2022 Recognize and replicate positive feedback patterns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data with topic assignments\n",
        "output_path = Path('data/processed/topic_assignments.csv')\n",
        "save_topic_assignments(df_clean, topic_result, output_path)\n",
        "\n",
        "# Save to parquet as well\n",
        "parquet_path = Path('data/processed/citizen_feedback_clean.parquet')\n",
        "df_clean.to_parquet(parquet_path, index=False)\n",
        "\n",
        "print(f'\u2713 Results saved to:')\n",
        "print(f'  - {output_path}')\n",
        "print(f'  - {parquet_path}')\n",
        "print(f'  - reports/figures/ (visualizations)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **Launch Dashboard**: Run `streamlit run dashboards/app.py` for interactive exploration\n",
        "2. **Review Policy Brief**: See `reports/citizen_feedback_brief.md` for recommendations\n",
        "3. **Documentation**: Review `docs/` folder for ethics, data dictionary, and modeling notes\n",
        "4. **Customization**: Adjust `config/analysis_config.yml` to experiment with parameters"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}